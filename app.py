# app.py
import streamlit as st
import os
import glob
from pathlib import Path
# import torch

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏ ---
st.set_page_config(layout="wide", page_title="–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞ –≤–∏–¥–µ–æ-–¥—É–±–ª—è–∂–∞")
st.title("üé¨ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞ –≤–∏–¥–µ–æ-–¥—É–±–ª—è–∂–∞")
st.write("–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤–∏–¥–µ–æ: –æ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞—É–¥–∏–æ –¥–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ä—É—Å—Å–∫–æ–π –æ–∑–≤—É—á–∫–∏ —Å –ø–æ–º–æ—â—å—é Zero-shot TTS.")

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ –ø—É—Ç–∏ ---
ARTIFACTS_ROOT = "pipeline_artifacts"
LIVE_DEMO_SAMPLES_ROOT = "live_demo_samples"
FINAL_VIDEO_ROOT = "final_video"
SPEAKERS = ["Bill_Gates", "Cameron_Russell"]


# --- –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —Ç—è–∂–µ–ª—ã—Ö –º–æ–¥–µ–ª–µ–π ---
# –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑
@st.cache_resource
def load_whisper_model():
    import whisper
    print("Loading Whisper model...")
    model = whisper.load_model("base")
    print("Whisper model loaded.")
    return model


@st.cache_resource
def load_translation_model():
    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
    print("Loading Translation model...")
    model_name = "Helsinki-NLP/opus-mt-en-ru"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
    print("Translation model loaded.")
    return tokenizer, model


@st.cache_resource
def load_tts_model():
    from TTS.api import TTS
    print("Loading TTS model...")
    # –£–∫–∞–∑—ã–≤–∞–µ–º gpu=False, —Ç–∞–∫ –∫–∞–∫ –Ω–∞ Streamlit Cloud –æ–±—ã—á–Ω–æ –Ω–µ—Ç GPU
    model = TTS("tts_models/multilingual/multi-dataset/xtts_v2", gpu=False)
    print("TTS model loaded.")
    return model


# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è Live –î–µ–º–æ ---
def run_live_pipeline(audio_path, voice_prompt_path):
    # 1. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
    st.write("–®–∞–≥ 1: –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ...")
    placeholder1 = st.empty()
    placeholder1.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper...")
    model_whisper = load_whisper_model()
    placeholder1.info("–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è...")
    result = model_whisper.transcribe(audio_path)
    english_text = result['text']
    placeholder1.success("–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    st.text_area("–ü–æ–ª—É—á–µ–Ω–Ω—ã–π –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç:", english_text, height=100)

    # 2. –ü–µ—Ä–µ–≤–æ–¥
    st.write("–®–∞–≥ 2: –ü–µ—Ä–µ–≤–æ–¥ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫...")
    placeholder2 = st.empty()
    placeholder2.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–≤–æ–¥–∞...")
    tokenizer_mt, model_mt = load_translation_model()
    placeholder2.info("–ü–µ—Ä–µ–≤–æ–¥...")
    input_ids = tokenizer_mt.encode(english_text, return_tensors="pt")
    outputs = model_mt.generate(input_ids)
    russian_text = tokenizer_mt.decode(outputs[0], skip_special_tokens=True)
    placeholder2.success("–ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    st.text_area("–ü–æ–ª—É—á–µ–Ω–Ω—ã–π —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç:", russian_text, height=100)

    # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ—á–∏ (TTS)
    st.write("–®–∞–≥ 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä—É—Å—Å–∫–æ–π –æ–∑–≤—É—á–∫–∏ (TTS)...")
    placeholder3 = st.empty()
    placeholder3.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ TTS (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç)...")
    model_tts = load_tts_model()
    placeholder3.warning("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ... –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ.")

    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ç–æ–Ω–∞—Ü–∏–æ–Ω–Ω—É—é –ø–∞—É–∑—É
    padded_text = f"... {russian_text}"

    output_tts_path = "live_demo_output.wav"
    model_tts.tts_to_file(
        text=padded_text,
        file_path=output_tts_path,
        speaker_wav=voice_prompt_path,
        language="ru"
    )
    placeholder3.success("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    st.audio(output_tts_path)

    return output_tts_path


# --- –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å ---

tab1, tab2 = st.tabs(["üîç –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≥–æ—Ç–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", "üöÄ Live –î–µ–º–æ"])

with tab1:
    st.header("–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≥–æ—Ç–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–∞–π–ø–ª–∞–π–Ω–∞")

    selected_speaker = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–∏–∫–µ—Ä–∞ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è:", SPEAKERS, key="speaker_select")

    if selected_speaker:
        st.subheader(f"–§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è: {selected_speaker}")

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("##### –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ")
            original_video_path = f"{selected_speaker}.mp4"
            if os.path.exists(original_video_path):
                st.video(original_video_path)
            else:
                st.warning("–§–∞–π–ª –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω.")

        with col2:
            st.markdown("##### –í–∏–¥–µ–æ —Å —Ä—É—Å—Å–∫–æ–π –æ–∑–≤—É—á–∫–æ–π")
            dubbed_video_path = os.path.join(FINAL_VIDEO_ROOT, f"{selected_speaker}_dubbed.mp4")
            if os.path.exists(dubbed_video_path):
                st.video(dubbed_video_path)
            else:
                st.warning("–§–∞–π–ª –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω.")

        st.divider()
        st.subheader("–ü–æ—à–∞–≥–æ–≤–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤")

        # --- –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä —á–∞–Ω–∫–∞ ---
        speaker_artifacts_path = os.path.join(ARTIFACTS_ROOT, selected_speaker)
        original_chunks_path = os.path.join(speaker_artifacts_path, "splited_audio_robust")

        if os.path.exists(original_chunks_path):
            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —á–∞–Ω–∫–∏ –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –∏—Ö
            chunk_files = glob.glob(os.path.join(original_chunks_path, "*.wav"))
            chunk_files.sort(key=lambda x: int(Path(x).stem.split('-')[-1]))

            if chunk_files:
                chunk_numbers = [Path(f).stem for f in chunk_files]
                selected_chunk_name = st.select_slider(
                    "–í—ã–±–µ—Ä–∏—Ç–µ —á–∞–Ω–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:",
                    options=chunk_numbers
                )

                # --- –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —á–∞–Ω–∫–µ ---
                chunk_num_str = selected_chunk_name.split('-')[-1]

                # 1. –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∞—É–¥–∏–æ—á–∞–Ω–∫
                st.markdown("##### 1. –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∞—É–¥–∏–æ—á–∞–Ω–∫ (–ø–æ—Å–ª–µ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏)")
                orig_audio_path = os.path.join(original_chunks_path, f"{selected_chunk_name}.wav")
                if os.path.exists(orig_audio_path):
                    st.audio(orig_audio_path)
                else:
                    st.error("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.")

                # 2. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
                st.markdown("##### 2. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è (Whisper)")
                transcription_path = os.path.join(speaker_artifacts_path, "transcriptions", f"{selected_chunk_name}.txt")
                if os.path.exists(transcription_path):
                    with open(transcription_path, 'r', encoding='utf-8') as f:
                        st.text_area("–¢–µ–∫—Å—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º:", f.read(), height=100, key=f"trans_{selected_chunk_name}")
                else:
                    st.info("–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –¥–ª—è —ç—Ç–æ–≥–æ —á–∞–Ω–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç (–≤–µ—Ä–æ—è—Ç–Ω–æ, –≤ –Ω–µ–º –Ω–µ—Ç —Ä–µ—á–∏).")

                # 3. –ü–µ—Ä–µ–≤–æ–¥
                st.markdown("##### 3. –ü–µ—Ä–µ–≤–æ–¥ (Helsinki-NLP)")
                translation_path = os.path.join(speaker_artifacts_path, "translations", f"{selected_chunk_name}.txt")
                if os.path.exists(translation_path):
                    with open(translation_path, 'r', encoding='utf-8') as f:
                        st.text_area("–¢–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º:", f.read(), height=100, key=f"trans_ru_{selected_chunk_name}")
                else:
                    st.info("–ü–µ—Ä–µ–≤–æ–¥ –¥–ª—è —ç—Ç–æ–≥–æ —á–∞–Ω–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.")

                # 4. –î—É–±–ª—è–∂
                st.markdown("##### 4. –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥—É–±–ª—è–∂ (XTTSv2)")
                dubbed_audio_path = os.path.join(speaker_artifacts_path, "dubbed_audio", f"{selected_chunk_name}.wav")
                if os.path.exists(dubbed_audio_path):
                    st.audio(dubbed_audio_path)
                else:
                    st.info("–î—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª –¥–ª—è —ç—Ç–æ–≥–æ —á–∞–Ω–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.")
            else:
                st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –∞—É–¥–∏–æ—á–∞–Ω–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
        else:
            st.error(f"–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–∞–ø–∫–∞ —Å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º–∏: {original_chunks_path}")


with tab2:
    st.header("Live –î–µ–º–æ –Ω–∞ –∫–æ—Ä–æ—Ç–∫–æ–º –∞—É–¥–∏–æ—Ñ—Ä–∞–≥–º–µ–Ω—Ç–µ")
    st.info("–ó–¥–µ—Å—å –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø–∞–π–ø–ª–∞–π–Ω –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –Ω–µ–±–æ–ª—å—à–æ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª–µ. –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç.")

    sample_files = glob.glob(os.path.join(LIVE_DEMO_SAMPLES_ROOT, "*.wav"))
    sample_names = [Path(f).name for f in sample_files]

    if sample_files:
        selected_sample_name = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∞—É–¥–∏–æ—Ñ—Ä–∞–≥–º–µ–Ω—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:", sample_names)
        selected_sample_path = os.path.join(LIVE_DEMO_SAMPLES_ROOT, selected_sample_name)

        st.write("–ò—Å—Ö–æ–¥–Ω—ã–π –∞—É–¥–∏–æ—Ñ—Ä–∞–≥–º–µ–Ω—Ç:")
        st.audio(selected_sample_path)

        st.write("–î–ª—è –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º –æ–±—Ä–∞–∑–µ—Ü. –í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–∏–∫–µ—Ä–∞, —á–µ–π –≥–æ–ª–æ—Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:")
        voice_speaker = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å:", SPEAKERS, key="voice_select")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ "–∑–æ–ª–æ—Ç–æ–º—É" –ø—Ä–æ–º–ø—Ç—É
        if voice_speaker == "Bill_Gates":
            voice_prompt_path = os.path.join(ARTIFACTS_ROOT, voice_speaker, "splited_audio_robust", f"{voice_speaker}-chunk-3.wav")
        elif voice_speaker == "Cameron_Russell":
            voice_prompt_path = os.path.join(ARTIFACTS_ROOT, voice_speaker, "splited_audio_robust", f"{voice_speaker}-chunk-5.wav")

        st.write(f"–ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –≥–æ–ª–æ—Å –∏–∑ —Ñ–∞–π–ª–∞: `{os.path.basename(voice_prompt_path)}`")
        st.audio(voice_prompt_path)

        if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–∞–π–ø–ª–∞–π–Ω!"):
            with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –¥–æ 5 –º–∏–Ω—É—Ç."):
                run_live_pipeline(selected_sample_path, voice_prompt_path)

    else:
        st.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã –∞—É–¥–∏–æ—Å–µ–º–ø–ª—ã –≤ –ø–∞–ø–∫–µ '{LIVE_DEMO_SAMPLES_ROOT}'.")
